{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "793f91b7",
   "metadata": {},
   "source": [
    "# Matrix Factorization Model\n",
    "This notebook trains a Matrix Factorization model (Truncated SVD) for a game recommendation system based on user interaction data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bd33a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import os\n",
    "import pickle\n",
    "import gc\n",
    "\n",
    "# Configuration\n",
    "pd.set_option('display.max_columns', None)\n",
    "BASE_DIR = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a971609",
   "metadata": {},
   "source": [
    "## Step 2: Load Datasets\n",
    "Load the user recommendation data and game metadata from CSV files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a02cac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Datasets\n",
    "recommendations_path = os.path.join(BASE_DIR, \"data/external/recommendations.csv\")\n",
    "games_path = os.path.join(BASE_DIR, \"data/external/games_tagged.csv\")\n",
    "\n",
    "print(f\"Loading recommendations from: {recommendations_path}\")\n",
    "df = pd.read_csv(recommendations_path)\n",
    "\n",
    "print(f\"Loading game metadata from: {games_path}\")\n",
    "games = pd.read_csv(games_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49be48d9",
   "metadata": {},
   "source": [
    "## Step 3: Create Interaction Score\n",
    "Build a custom interaction score combining hours played, review helpfulness, and recommendation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9a035f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Interaction Score\n",
    "print(\"\\nCreating interaction score...\")\n",
    "df['hours_log'] = df['hours_log'].fillna(0)\n",
    "df['helpfulness_ratio'] = df['helpfulness_ratio'].fillna(0)\n",
    "df['interaction'] = (\n",
    "    0.6 * df['hours_log'] +\n",
    "    0.3 * df['is_recommended_binary'] +\n",
    "    0.1 * df['helpfulness_ratio']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343f7b17",
   "metadata": {},
   "source": [
    "## Step 4: Filter Active Users and Items\n",
    "Remove inactive users and unpopular games to reduce noise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079b6f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter Active Users and Items\n",
    "print(\"\\nFiltering active users and active items...\")\n",
    "user_interaction_counts = df['user_id'].value_counts()\n",
    "item_interaction_counts = df['app_id'].value_counts()\n",
    "\n",
    "MIN_USER_INTERACTIONS = 5\n",
    "MIN_ITEM_INTERACTIONS = 500\n",
    "\n",
    "users_to_keep = user_interaction_counts[user_interaction_counts >= MIN_USER_INTERACTIONS].index\n",
    "items_to_keep = item_interaction_counts[item_interaction_counts >= MIN_ITEM_INTERACTIONS].index\n",
    "\n",
    "df = df[df['user_id'].isin(users_to_keep) & df['app_id'].isin(items_to_keep)]\n",
    "print(f\"Data after filtering: {len(df):,} records.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a3b047",
   "metadata": {},
   "source": [
    "## Step 5: Create User-Item Interaction Matrix\n",
    "Pivot the data into a matrix where rows = users and columns = items (games).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302a5253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create User-Item Interaction Matrix\n",
    "print(\"\\nCreating user-item interaction matrix...\")\n",
    "user_item_matrix = df.pivot_table(index='user_id', columns='app_id', values='interaction', fill_value=0)\n",
    "print(f\"User-item matrix shape: {user_item_matrix.shape}\")\n",
    "\n",
    "R_full = user_item_matrix.values\n",
    "user_ids = list(user_item_matrix.index)\n",
    "item_ids = list(user_item_matrix.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afd8b79",
   "metadata": {},
   "source": [
    "## Step 6: Train-Test Split\n",
    "Randomly hide 20% of interactions to evaluate model performance later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf5b27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test Split\n",
    "print(\"\\nSplitting into train and test sets...\")\n",
    "np.random.seed(42)\n",
    "test_mask = np.random.rand(*R_full.shape) < 0.2\n",
    "train_matrix = R_full.copy()\n",
    "train_matrix[test_mask] = 0\n",
    "\n",
    "print(f\"Train matrix non-zero entries: {np.count_nonzero(train_matrix):,}\")\n",
    "print(f\"Test matrix non-zero entries: {np.count_nonzero(test_mask):,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102f83db",
   "metadata": {},
   "source": [
    "## Step 7: Train Matrix Factorization Model\n",
    "Use Truncated SVD to learn user and item latent factors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266ce1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Matrix Factorization Model\n",
    "print(\"\\nTraining TruncatedSVD model...\")\n",
    "n_components = min(20, train_matrix.shape[1] - 1)\n",
    "print(f\"Using n_components = {n_components}\")\n",
    "svd = TruncatedSVD(n_components=n_components, random_state=42)\n",
    "user_factors = svd.fit_transform(train_matrix)\n",
    "item_factors = svd.components_\n",
    "\n",
    "# Predict Ratings\n",
    "R_pred = np.dot(user_factors, item_factors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5ce3bd",
   "metadata": {},
   "source": [
    "## Step 8: Evaluate RMSE and MAE\n",
    "Measure prediction error on the hidden (test) set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf05bbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate RMSE and MAE\n",
    "print(\"\\nEvaluating RMSE and MAE...\")\n",
    "rmse = np.sqrt(mean_squared_error(R_full[test_mask], R_pred[test_mask]))\n",
    "mae = mean_absolute_error(R_full[test_mask], R_pred[test_mask])\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1011a7",
   "metadata": {},
   "source": [
    "## Step 9: Prepare Binary Matrix for Evaluation\n",
    "Prepare a binary version of the matrix (recommended/not recommended) for classification evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d63726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Binary Matrix\n",
    "print(\"\\nPreparing binary matrix for evaluation...\")\n",
    "binary_matrix = df.pivot_table(index='user_id', columns='app_id', values='is_recommended_binary', fill_value=0)\n",
    "binary_matrix = binary_matrix.loc[user_item_matrix.index, user_item_matrix.columns]\n",
    "R_true_binary = binary_matrix.values\n",
    "R_test_binary = np.where(test_mask, R_true_binary, 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bf665c",
   "metadata": {},
   "source": [
    "## Step 10: Evaluate Precision@20, Recall@20, F1@20\n",
    "Evaluate recommendation quality at top 20 predicted games.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259fc67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision, Recall, F1 Evaluation\n",
    "print(\"\\nEvaluating Precision@20, Recall@20, F1@20...\")\n",
    "\n",
    "def precision_recall_f1_at_k(R_true, R_pred, k=20):\n",
    "    precisions, recalls, f1s = [], [], []\n",
    "    for i in range(R_true.shape[0]):\n",
    "        actual = set(np.where(R_true[i] > 0)[0])\n",
    "        if not actual:\n",
    "            continue\n",
    "        pred_scores = R_pred[i].copy()\n",
    "        top_k = set(np.argsort(pred_scores)[-k:])\n",
    "        tp = len(actual & top_k)\n",
    "        precision = tp / k if k else 0\n",
    "        recall = tp / len(actual) if actual else 0\n",
    "        f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        f1s.append(f1)\n",
    "    return np.mean(precisions), np.mean(recalls), np.mean(f1s)\n",
    "\n",
    "precision, recall, f1 = precision_recall_f1_at_k(R_test_binary, R_pred, k=20)\n",
    "print(f\"Precision@20: {precision:.4f}\")\n",
    "print(f\"Recall@20:    {recall:.4f}\")\n",
    "print(f\"F1@20:        {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd28e180",
   "metadata": {},
   "source": [
    "## Step 11: Save Model Artifacts\n",
    "Save the item latent factors and item IDs to disk for future use in the Streamlit app.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f0db0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model Artifacts\n",
    "print(\"\\nSaving model artifacts...\")\n",
    "\n",
    "models_dir = os.path.join(BASE_DIR, \"models\")\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "np.save(os.path.join(models_dir, \"item_factors.npy\"), item_factors.T)  # Save item latent vectors\n",
    "with open(os.path.join(models_dir, \"item_ids.pkl\"), 'wb') as f:\n",
    "    pickle.dump(item_ids, f)\n",
    "\n",
    "print(f\"Saved item_factors.npy and item_ids.pkl to {models_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682b5cf2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889a0a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 11: Calculate Item-Item Cosine Similarity\n",
    "\n",
    "print(\"\\nCalculating item-item cosine similarity...\")\n",
    "\n",
    "item_factors_T = item_factors.T  # Transpose so rows = games\n",
    "item_similarity_matrix = cosine_similarity(item_factors_T)\n",
    "\n",
    "print(f\"Item-Item Similarity Matrix Shape: {item_similarity_matrix.shape}\")\n",
    "\n",
    "# Step 12: Recommend Top-N Similar Games for Each Game\n",
    "\n",
    "top_n = 10  # How many similar games you want to recommend\n",
    "all_game_recommendations = []\n",
    "\n",
    "print(\"\\nGenerating Top-10 similar games for each game...\")\n",
    "\n",
    "# Create app_id mappings\n",
    "index_to_app_id = {idx: app_id for idx, app_id in enumerate(item_ids)}\n",
    "app_id_to_title = games.set_index('app_id')['title'].to_dict()\n",
    "\n",
    "for game_idx in range(item_similarity_matrix.shape[0]):\n",
    "    game_id = index_to_app_id.get(game_idx)\n",
    "    game_title = app_id_to_title.get(game_id, \"Unknown Title\")\n",
    "\n",
    "    # Get similarity scores for this game\n",
    "    similarities = item_similarity_matrix[game_idx]\n",
    "\n",
    "    # Get top N similar games (excluding itself)\n",
    "    similar_indices = similarities.argsort()[::-1][1:top_n+1]  # Skip the first one (itself)\n",
    "\n",
    "    print(f\"\\nTop {top_n} similar games for '{game_title}' (Game ID: {game_id}):\")\n",
    "    for rank, sim_idx in enumerate(similar_indices, start=1):\n",
    "        similar_game_id = index_to_app_id.get(sim_idx)\n",
    "        similar_game_title = app_id_to_title.get(similar_game_id, \"Unknown Title\")\n",
    "        similarity_score = similarities[sim_idx]\n",
    "        print(f\"  {rank}. {similar_game_title} (Game ID: {similar_game_id}, Similarity: {similarity_score:.4f})\")\n",
    "\n",
    "        all_game_recommendations.append({\n",
    "            \"Game ID\": game_id,\n",
    "            \"Game Title\": game_title,\n",
    "            \"Similar Game ID\": similar_game_id,\n",
    "            \"Similar Game Title\": similar_game_title,\n",
    "            \"Similarity Score\": similarity_score\n",
    "        })\n",
    "\n",
    "# Step 13: Save all Top-N similar games into a CSV\n",
    "\n",
    "output_dir = os.path.join(BASE_DIR, \"models\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "similar_games_csv_path = os.path.join(output_dir, \"top10_similar_games_mf.csv\")\n",
    "similar_games_df = pd.DataFrame(all_game_recommendations)\n",
    "similar_games_df.to_csv(similar_games_csv_path, index=False)\n",
    "\n",
    "print(f\"\\nSaved Top-10 similar games for all games to: {similar_games_csv_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
