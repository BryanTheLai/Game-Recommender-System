{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3d1f58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading recommendations from: c:\\Users\\wbrya\\OneDrive\\Documents\\GitHub\\MovieLens-Recommender-System\\data/external/recommendations.csv\n",
      "Loaded 41,154,794 full recommendations records.\n",
      "Loading game metadata from: c:\\Users\\wbrya\\OneDrive\\Documents\\GitHub\\MovieLens-Recommender-System\\data/external/games_tagged.csv\n",
      "Loaded 50,872 games metadata records.\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Import Libraries and Load Full Data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix # Will be used later\n",
    "import os\n",
    "\n",
    "# --- Configuration ---\n",
    "pd.set_option('display.max_columns', None)\n",
    "BASE_DIR = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "# --- Load Data ---\n",
    "recommendations_path = os.path.join(BASE_DIR, \"data/external/recommendations.csv\")\n",
    "games_path = os.path.join(BASE_DIR, \"data/external/games_tagged.csv\")\n",
    "\n",
    "# --- Load Full Recommendations Data ---\n",
    "print(f\"Loading recommendations from: {recommendations_path}\")\n",
    "recommendations_pd_full = pd.read_csv(recommendations_path)\n",
    "recommendations_pd_full['app_id'] = recommendations_pd_full['app_id'].astype(int)\n",
    "print(f\"Loaded {len(recommendations_pd_full):,} full recommendations records.\")\n",
    "\n",
    "# --- Load Game Metadata ---\n",
    "print(f\"Loading game metadata from: {games_path}\")\n",
    "games_pd = pd.read_csv(games_path)\n",
    "games_pd['app_id'] = games_pd['app_id'].astype(int)\n",
    "print(f\"Loaded {len(games_pd):,} games metadata records.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e73726c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating interaction counts...\n",
      "Found 13,781,059 unique users.\n",
      "Found 37,610 unique items (games) with interactions.\n",
      "\n",
      "User Interaction Count Stats:\n",
      "count    1.378106e+07\n",
      "mean     2.986330e+00\n",
      "std      8.118011e+00\n",
      "min      1.000000e+00\n",
      "25%      1.000000e+00\n",
      "50%      1.000000e+00\n",
      "75%      3.000000e+00\n",
      "max      6.045000e+03\n",
      "Name: count, dtype: float64\n",
      "\n",
      "Item Interaction Count Stats:\n",
      "count     37610.000000\n",
      "mean       1094.251369\n",
      "std        7689.340463\n",
      "min           1.000000\n",
      "25%          13.000000\n",
      "50%          39.000000\n",
      "75%         179.750000\n",
      "max      319492.000000\n",
      "Name: count, dtype: float64\n",
      "\n",
      "Top 5 Users by Interactions:\n",
      "user_id\n",
      "11764552    6045\n",
      "5112758     4152\n",
      "11656130    3840\n",
      "5669734     3479\n",
      "11553593    3392\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Top 5 Items by Interactions:\n",
      "app_id\n",
      "440        319492\n",
      "252490     270684\n",
      "1091500    226414\n",
      "730        219737\n",
      "570        216914\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Calculate Interaction Counts on Full Dataset\n",
    "print(\"Calculating interaction counts...\")\n",
    "\n",
    "# Count how many interactions each user has\n",
    "user_interaction_counts = recommendations_pd_full['user_id'].value_counts()\n",
    "\n",
    "# Count how many interactions each game (app_id) has\n",
    "item_interaction_counts = recommendations_pd_full['app_id'].value_counts()\n",
    "\n",
    "print(f\"Found {len(user_interaction_counts):,} unique users.\")\n",
    "print(f\"Found {len(item_interaction_counts):,} unique items (games) with interactions.\")\n",
    "\n",
    "# Display some stats about the counts (optional, but helpful for choosing thresholds)\n",
    "print(\"\\nUser Interaction Count Stats:\")\n",
    "print(user_interaction_counts.describe())\n",
    "print(\"\\nItem Interaction Count Stats:\")\n",
    "print(item_interaction_counts.describe())\n",
    "\n",
    "# Example: See the top 5 most active users and most interacted-with games\n",
    "print(\"\\nTop 5 Users by Interactions:\")\n",
    "print(user_interaction_counts.head())\n",
    "print(\"\\nTop 5 Items by Interactions:\")\n",
    "print(item_interaction_counts.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e017360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering criteria: Users >= 10 interactions, Items >= 10000 interactions.\n",
      "Interactions after user filtering: 14,600,426\n",
      "Interactions after item filtering: 8,289,865\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 3: Filter Interactions Based on Thresholds\n",
    "\n",
    "# --- Define Thresholds ---\n",
    "MIN_USER_INTERACTIONS = 10  # Keep users who interacted with at least 10 games\n",
    "MIN_ITEM_INTERACTIONS = 10000 # Keep games that were interacted with by at least 10000 users\n",
    "\n",
    "print(f\"Filtering criteria: Users >= {MIN_USER_INTERACTIONS} interactions, Items >= {MIN_ITEM_INTERACTIONS} interactions.\")\n",
    "\n",
    "# --- Filter Users ---\n",
    "# Get the list of user_ids who meet the minimum interaction count\n",
    "users_to_keep = user_interaction_counts[user_interaction_counts >= MIN_USER_INTERACTIONS].index\n",
    "# Filter the main dataframe\n",
    "recommendations_pd_filtered_users = recommendations_pd_full[recommendations_pd_full['user_id'].isin(users_to_keep)]\n",
    "print(f\"Interactions after user filtering: {len(recommendations_pd_filtered_users):,}\")\n",
    "\n",
    "# --- Filter Items ---\n",
    "# Get the list of app_ids that meet the minimum interaction count\n",
    "items_to_keep = item_interaction_counts[item_interaction_counts >= MIN_ITEM_INTERACTIONS].index\n",
    "# Filter the dataframe that was already filtered by user\n",
    "recommendations_pd_filtered = recommendations_pd_filtered_users[recommendations_pd_filtered_users['app_id'].isin(items_to_keep)]\n",
    "print(f\"Interactions after item filtering: {len(recommendations_pd_filtered):,}\")\n",
    "\n",
    "# --- Cleanup intermediate variable (optional) ---\n",
    "del items_to_keep # Index object\n",
    "del item_interaction_counts # Series\n",
    "del recommendations_pd_filtered_users # DataFrame (intermediate step)\n",
    "del recommendations_pd_full # DataFrame (original full data)\n",
    "\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b9e0ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtered interaction count: 8,289,865\n",
      "Final number of interactions being used (shuffled): 8,289,865\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 4: Sample from Filtered Data\n",
    "\n",
    "SEED = 42\n",
    "print(f\"\\nFiltered interaction count: {len(recommendations_pd_filtered):,}\")\n",
    "recommendations_pd_final = recommendations_pd_filtered.sample(frac=1, random_state=SEED)\n",
    "\n",
    "print(f\"Final number of interactions being used (shuffled): {len(recommendations_pd_final):,}\")\n",
    "\n",
    "# --- Cleanup intermediate variable (optional) ---\n",
    "del recommendations_pd_filtered\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfa62b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Final Recommendations Data (Filtered & Shuffled):\n",
      "           app_id  helpful  funny   user_id  review_id  hours_log  \\\n",
      "11388928   301640        0      0   8200358   11388928   0.182322   \n",
      "6423607   1238840        6      0   6700445    6423607   2.509599   \n",
      "12776548  1252330        0      0   5091898   12776548   1.887070   \n",
      "24633783   356190        0      0  10368619   24633783   0.095310   \n",
      "12428935  1167630        0      0   1001456   12428935   3.288402   \n",
      "\n",
      "          hours_log_scaled  is_recommended_binary  review_year  review_month  \\\n",
      "11388928         -1.930017                      1         2018             3   \n",
      "6423607          -0.530183                      1         2020            11   \n",
      "12776548         -0.904629                      0         2021            12   \n",
      "24633783         -1.982353                      0         2020            10   \n",
      "12428935         -0.061742                      1         2021            12   \n",
      "\n",
      "          review_day  review_age_years  helpfulness_ratio  helpful_log  \\\n",
      "11388928           8          6.819986           0.000000      0.00000   \n",
      "6423607           25          4.101300           0.857143      1.94591   \n",
      "12776548          28          3.011636           0.000000      0.00000   \n",
      "24633783           9          4.229979           0.000000      0.00000   \n",
      "12428935          19          3.036277           0.000000      0.00000   \n",
      "\n",
      "          funny_log  \n",
      "11388928        0.0  \n",
      "6423607         0.0  \n",
      "12776548        0.0  \n",
      "24633783        0.0  \n",
      "12428935        0.0  \n",
      "\n",
      "Unique Games in final dataset: 738\n",
      "\n",
      "Filtering Games Metadata...\n",
      "Retained metadata for 738 games.\n",
      "\n",
      "Sample Filtered Games Metadata (Relevant Columns):\n",
      "     app_id                title  \\\n",
      "155  755790      Ring of Elysium   \n",
      "194  582500         We Were Here   \n",
      "223  221910  The Stanley Parable   \n",
      "480  552520           Far Cry® 5   \n",
      "648   41070   Serious Sam 3: BFE   \n",
      "\n",
      "                                                  tags  \n",
      "155  ['Free to Play', 'Battle Royale', 'Shooter', '...  \n",
      "194  ['Free to Play', 'Co-op', 'Escape Room', 'Puzz...  \n",
      "223  ['Comedy', 'Narration', 'Indie', 'Walking Simu...  \n",
      "480                                                 []  \n",
      "648  ['FPS', 'Action', 'Co-op', 'Gore', 'Comedy', '...  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 5: Display Sample Data and Finalize Game Metadata\n",
    "\n",
    "print(\"\\nSample Final Recommendations Data (Filtered & Shuffled):\")\n",
    "print(recommendations_pd_final.head())\n",
    "\n",
    "# Get unique game IDs from the final interaction dataset\n",
    "final_game_ids = recommendations_pd_final['app_id'].unique()\n",
    "print(f\"\\nUnique Games in final dataset: {len(final_game_ids):,}\")\n",
    "\n",
    "print(\"\\nFiltering Games Metadata...\")\n",
    "# Keep only metadata for games present in the final interaction data\n",
    "games_pd_filtered = games_pd[games_pd['app_id'].isin(final_game_ids)]\n",
    "print(f\"Retained metadata for {len(games_pd_filtered):,} games.\")\n",
    "\n",
    "print(\"\\nSample Filtered Games Metadata (Relevant Columns):\")\n",
    "print(games_pd_filtered[['app_id', 'title', 'tags']].head())\n",
    "\n",
    "# --- Final Cleanup for this Stage ---\n",
    "# Overwrite the original games_pd with the filtered version\n",
    "games_pd = games_pd_filtered\n",
    "\n",
    "# Delete the intermediate filtered variable and the IDs list\n",
    "del games_pd_filtered\n",
    "del final_game_ids\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6ca0493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the User-Item interaction matrix...\n",
      "Input data shape: (8289865, 15)\n",
      "Created pivot table with shape: (678264, 738) (Users x Items)\n",
      "Converting pivot table to sparse matrix (CSR format)...\n",
      "Sparse matrix shape: (678264, 738)\n",
      "Sparsity: 98.3439%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 6: Create User-Item Interaction Matrix\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "print(\"Creating the User-Item interaction matrix...\")\n",
    "print(f\"Input data shape: {recommendations_pd_final.shape}\")\n",
    "\n",
    "# Define the interaction value column\n",
    "interaction_value_col = 'hours_log_scaled'\n",
    "\n",
    "# Use pivot_table to create the matrix (Users as rows, Items as columns)\n",
    "user_item_pivot = recommendations_pd_final.pivot_table(\n",
    "    index='user_id',\n",
    "    columns='app_id',\n",
    "    values=interaction_value_col,\n",
    "    fill_value=0  # Fill missing interactions (NaN) with 0\n",
    ")\n",
    "\n",
    "print(f\"Created pivot table with shape: {user_item_pivot.shape} (Users x Items)\")\n",
    "\n",
    "# Convert the dense pivot table to a sparse matrix (CSR format)\n",
    "print(\"Converting pivot table to sparse matrix (CSR format)...\")\n",
    "user_item_sparse_matrix = csr_matrix(user_item_pivot.values)\n",
    "\n",
    "# --- Create Mappings for Interpretation ---\n",
    "# These maps are essential to link matrix rows/columns back to original IDs\n",
    "user_map = {id: i for i, id in enumerate(user_item_pivot.index)}\n",
    "item_map = {id: i for i, id in enumerate(user_item_pivot.columns)}\n",
    "\n",
    "# Create inverse mappings to get IDs from matrix indices\n",
    "user_map_inv = {i: id for id, i in user_map.items()}\n",
    "item_map_inv = {i: id for id, i in item_map.items()}\n",
    "\n",
    "print(f\"Sparse matrix shape: {user_item_sparse_matrix.shape}\")\n",
    "sparsity = 1.0 - user_item_sparse_matrix.nnz / (user_item_sparse_matrix.shape[0] * user_item_sparse_matrix.shape[1])\n",
    "print(f\"Sparsity: {sparsity:.4%}\")\n",
    "\n",
    "# --- Cleanup ---\n",
    "del user_item_pivot\n",
    "del recommendations_pd_final\n",
    "\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b53e198d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Item-Item cosine similarity...\n",
      "Calculated item-item similarity matrix with shape: (738, 738)\n",
      "Diagonal check (should be close to 1): 0.9999999999999977\n",
      "\n",
      "Slice of the similarity matrix:\n",
      "          0         1         2         3         4\n",
      "0  1.000000  0.052652  0.091838  0.042068  0.089529\n",
      "1  0.052652  1.000000  0.086355  0.170226  0.045969\n",
      "2  0.091838  0.086355  1.000000  0.066886  0.074018\n",
      "3  0.042068  0.170226  0.066886  1.000000  0.055073\n",
      "4  0.089529  0.045969  0.074018  0.055073  1.000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 7: Calculate Item-Item Cosine Similarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "print(\"Calculating Item-Item cosine similarity...\")\n",
    "\n",
    "# Important: cosine_similarity expects samples as rows.\n",
    "# Our user_item_sparse_matrix has users as rows and items as columns.\n",
    "# To calculate item-item similarity, we need to compare the columns.\n",
    "# Therefore, we transpose the matrix (.T) so that items become rows.\n",
    "item_user_sparse_matrix = user_item_sparse_matrix.T\n",
    "\n",
    "# Calculate cosine similarity between all pairs of items (rows in the transposed matrix)\n",
    "# This returns a dense numpy array (item_count x item_count)\n",
    "item_similarity_matrix = cosine_similarity(item_user_sparse_matrix, dense_output=True) # Keep dense for easier lookup\n",
    "\n",
    "# The resulting item_similarity_matrix is a square matrix where:\n",
    "# - Rows and columns both correspond to item indices (0 to 737 in your case).\n",
    "# - The value at matrix[i, j] is the cosine similarity between item i and item j.\n",
    "# - The diagonal (matrix[i, i]) will always be 1 (similarity of an item with itself).\n",
    "\n",
    "print(f\"Calculated item-item similarity matrix with shape: {item_similarity_matrix.shape}\")\n",
    "\n",
    "# Optional: Verify the diagonal is all 1s (within floating point tolerance)\n",
    "print(f\"Diagonal check (should be close to 1): {item_similarity_matrix.diagonal().mean()}\")\n",
    "\n",
    "# Optional: Display a small slice of the similarity matrix\n",
    "print(\"\\nSlice of the similarity matrix:\")\n",
    "print(pd.DataFrame(item_similarity_matrix).iloc[:5, :5])\n",
    "\n",
    "# --- Cleanup ---\n",
    "del item_user_sparse_matrix\n",
    "del user_item_sparse_matrix\n",
    "\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "608b7f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing recommendation function with app_id: 240\n",
      "   app_id                       game_name  similarity_score\n",
      "0      10                  Counter-Strike          0.089529\n",
      "1      80  Counter-Strike: Condition Zero          0.074018\n",
      "2     500                     Left 4 Dead          0.070424\n",
      "3     220                     Half-Life 2          0.055073\n",
      "4     550                   Left 4 Dead 2          0.048502\n",
      "5      70                       Half-Life          0.045969\n",
      "6     400                          Portal          0.035202\n",
      "7    1250                   Killing Floor          0.034644\n",
      "8     620                        Portal 2          0.031148\n",
      "9     380        Half-Life 2: Episode One          0.028551\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Define Item-Based Recommendation Function using Cosine Similarity\n",
    "\n",
    "def recommend_similar_games_cosine(target_app_id: int, top_n: int = 10) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Recommends games similar to the target_app_id using the pre-calculated\n",
    "    item-item cosine similarity matrix.\n",
    "\n",
    "    Args:\n",
    "        target_app_id: The app_id of the game for which to find recommendations.\n",
    "        top_n: The number of similar games to return.\n",
    "\n",
    "    Returns:\n",
    "        A pandas DataFrame containing the top_n recommended games, including\n",
    "        their app_id, game_name, and similarity_score. Returns an empty\n",
    "        DataFrame if the target_app_id is not found in the model's data.\n",
    "    \"\"\"\n",
    "    # --- Input Validation ---\n",
    "    if target_app_id not in item_map:\n",
    "        print(f\"Warning: app_id {target_app_id} not found in the filtered interaction data used for the model.\")\n",
    "        # Return empty DataFrame with correct columns\n",
    "        return pd.DataFrame(columns=['app_id', 'game_name', 'similarity_score'])\n",
    "\n",
    "    # --- Get Matrix Index ---\n",
    "    try:\n",
    "        item_index = item_map[target_app_id]\n",
    "    except KeyError:\n",
    "        # This case should be covered by the initial check, but added for robustness\n",
    "        print(f\"Error: Could not find matrix index for app_id {target_app_id}.\")\n",
    "        return pd.DataFrame(columns=['app_id', 'game_name', 'similarity_score'])\n",
    "\n",
    "\n",
    "    # --- Retrieve Similarity Scores ---\n",
    "    # Get the similarity scores of the target item with all other items\n",
    "    similarity_scores = item_similarity_matrix[item_index] # This is a numpy array\n",
    "\n",
    "    # --- Combine Scores with Item Indices ---\n",
    "    # Create a list of tuples: (item_matrix_index, similarity_score)\n",
    "    # We use enumerate to get both index and score\n",
    "    item_score_pairs = list(enumerate(similarity_scores))\n",
    "\n",
    "    # --- Sort by Similarity ---\n",
    "    # Sort the list in descending order based on score (the second element of the tuple)\n",
    "    sorted_item_score_pairs = sorted(item_score_pairs, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # --- Exclude Input Game & Select Top N ---\n",
    "    # The first item in the sorted list will be the target_app_id itself (similarity=1)\n",
    "    # So, we skip the first one and take the next top_n\n",
    "    top_similar_items = sorted_item_score_pairs[1 : top_n + 1] # Slice includes start, excludes end\n",
    "\n",
    "    # --- Map Indices back to App IDs and Get Names ---\n",
    "    recommendations = []\n",
    "    for matrix_idx, score in top_similar_items:\n",
    "        try:\n",
    "            recommended_app_id = item_map_inv[matrix_idx]\n",
    "            # Look up game title in our filtered games_pd\n",
    "            game_info = games_pd[games_pd['app_id'] == recommended_app_id]\n",
    "            if not game_info.empty:\n",
    "                 game_name = game_info['title'].iloc[0]\n",
    "            else:\n",
    "                 game_name = \"Title Not Found\" # Fallback if somehow missing\n",
    "            recommendations.append({\n",
    "                'app_id': recommended_app_id,\n",
    "                'game_name': game_name,\n",
    "                'similarity_score': score\n",
    "            })\n",
    "        except KeyError:\n",
    "             # Should not happen if item_map_inv is correct, but good practice\n",
    "             print(f\"Warning: Could not map matrix index {matrix_idx} back to an app_id.\")\n",
    "        except IndexError:\n",
    "             # If game_info was unexpectedly empty\n",
    "             print(f\"Warning: Could not retrieve game title for app_id {recommended_app_id}\")\n",
    "\n",
    "\n",
    "    return pd.DataFrame(recommendations)\n",
    "\n",
    "# --- Quick Test ---\n",
    "# Find a game ID that is definitely in our data\n",
    "if 'item_map' in globals() and item_map: # Check if item_map exists and is not empty\n",
    "    test_id = list(item_map.keys())[4] # Get the first app_id from our map\n",
    "    print(f\"Testing recommendation function with app_id: {test_id}\")\n",
    "    sample_recommendations = recommend_similar_games_cosine(test_id, top_n=10)\n",
    "    print(sample_recommendations)\n",
    "else:\n",
    "    print(\"Skipping function test as item_map is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110c4bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model artifacts...\n",
      "Saved item similarity matrix to: c:\\Users\\wbrya\\OneDrive\\Documents\\GitHub\\MovieLens-Recommender-System\\models\\item_similarity_matrix.pkl\n",
      "Saved item map to: c:\\Users\\wbrya\\OneDrive\\Documents\\GitHub\\MovieLens-Recommender-System\\models\\item_map.pkl\n",
      "Saved inverse item map to: c:\\Users\\wbrya\\OneDrive\\Documents\\GitHub\\MovieLens-Recommender-System\\models\\item_map_inv.pkl\n",
      "Saved filtered games metadata DataFrame to: c:\\Users\\wbrya\\OneDrive\\Documents\\GitHub\\MovieLens-Recommender-System\\models\\filtered_games_metadata.pkl\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Save Model Artifacts for Streamlit App\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "print(\"Saving model artifacts...\")\n",
    "\n",
    "# Define filenames for the artifacts\n",
    "similarity_matrix_filename = \"item_similarity_matrix.pkl\"\n",
    "item_map_filename = \"item_map.pkl\"\n",
    "item_map_inv_filename = \"item_map_inv.pkl\"\n",
    "games_df_filename = \"filtered_games_metadata.pkl\" # Save the filtered games_pd\n",
    "\n",
    "# Define the target directory (using the models directory from your structure)\n",
    "models_dir = os.path.join(BASE_DIR, \"models\")\n",
    "os.makedirs(models_dir, exist_ok=True) # Create the directory if it doesn't exist\n",
    "\n",
    "# --- Objects to Save ---\n",
    "# 1. The Item-Item Cosine Similarity Matrix (NumPy array)\n",
    "similarity_matrix_path = os.path.join(models_dir, similarity_matrix_filename)\n",
    "with open(similarity_matrix_path, 'wb') as f:\n",
    "    pickle.dump(item_similarity_matrix, f)\n",
    "print(f\"Saved item similarity matrix to: {similarity_matrix_path}\")\n",
    "\n",
    "# 2. Item Map (app_id -> matrix index dictionary)\n",
    "item_map_path = os.path.join(models_dir, item_map_filename)\n",
    "with open(item_map_path, 'wb') as f:\n",
    "    pickle.dump(item_map, f)\n",
    "print(f\"Saved item map to: {item_map_path}\")\n",
    "\n",
    "# 3. Inverse Item Map (matrix index -> app_id dictionary)\n",
    "item_map_inv_path = os.path.join(models_dir, item_map_inv_filename)\n",
    "with open(item_map_inv_path, 'wb') as f:\n",
    "    pickle.dump(item_map_inv, f)\n",
    "print(f\"Saved inverse item map to: {item_map_inv_path}\")\n",
    "\n",
    "# 4. Filtered Games DataFrame (pandas DataFrame)\n",
    "# This contains metadata ONLY for the games present in the similarity matrix\n",
    "games_df_path = os.path.join(models_dir, games_df_filename)\n",
    "# Ensure we're saving the final filtered games_pd from Cell 5\n",
    "with open(games_df_path, 'wb') as f:\n",
    "    pickle.dump(games_pd, f)\n",
    "print(f\"Saved filtered games metadata DataFrame to: {games_df_path}\")\n",
    "\n",
    "# --- Cleanup ---\n",
    "del item_map\n",
    "del item_map_inv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
