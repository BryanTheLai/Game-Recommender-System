{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3d1f58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading recommendations from: c:\\Users\\wbrya\\OneDrive\\Documents\\GitHub\\MovieLens-Recommender-System\\data/external/recommendations.csv\n",
      "Loaded 41,154,794 full recommendations records.\n",
      "Loading game metadata from: c:\\Users\\wbrya\\OneDrive\\Documents\\GitHub\\MovieLens-Recommender-System\\data/external/games_tagged.csv\n",
      "Loaded 50,872 games metadata records.\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Import Libraries and Load Full Data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import os\n",
    "import gc\n",
    "from typing import Dict, List, Tuple, Set\n",
    "import pickle\n",
    "\n",
    "# --- Configuration ---\n",
    "pd.set_option('display.max_columns', None)\n",
    "BASE_DIR = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "# --- Load Data ---\n",
    "recommendations_path = os.path.join(BASE_DIR, \"data/external/recommendations.csv\")\n",
    "games_path = os.path.join(BASE_DIR, \"data/external/games_tagged.csv\")\n",
    "\n",
    "# --- Load Full Recommendations Data ---\n",
    "print(f\"Loading recommendations from: {recommendations_path}\")\n",
    "recommendations_pd_full = pd.read_csv(recommendations_path)\n",
    "recommendations_pd_full['app_id'] = recommendations_pd_full['app_id'].astype(int)\n",
    "print(f\"Loaded {len(recommendations_pd_full):,} full recommendations records.\")\n",
    "\n",
    "# --- Load Game Metadata ---\n",
    "print(f\"Loading game metadata from: {games_path}\")\n",
    "games_pd = pd.read_csv(games_path)\n",
    "games_pd['app_id'] = games_pd['app_id'].astype(int)\n",
    "print(f\"Loaded {len(games_pd):,} games metadata records.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e73726c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating interaction counts...\n",
      "Found 13,781,059 unique users.\n",
      "Found 37,610 unique items (games) with interactions.\n",
      "\n",
      "User Interaction Count Stats:\n",
      "count    1.378106e+07\n",
      "mean     2.986330e+00\n",
      "std      8.118011e+00\n",
      "min      1.000000e+00\n",
      "25%      1.000000e+00\n",
      "50%      1.000000e+00\n",
      "75%      3.000000e+00\n",
      "max      6.045000e+03\n",
      "Name: count, dtype: float64\n",
      "\n",
      "Item Interaction Count Stats:\n",
      "count     37610.000000\n",
      "mean       1094.251369\n",
      "std        7689.340463\n",
      "min           1.000000\n",
      "25%          13.000000\n",
      "50%          39.000000\n",
      "75%         179.750000\n",
      "max      319492.000000\n",
      "Name: count, dtype: float64\n",
      "\n",
      "Top 5 Users by Interactions:\n",
      "user_id\n",
      "11764552    6045\n",
      "5112758     4152\n",
      "11656130    3840\n",
      "5669734     3479\n",
      "11553593    3392\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Top 5 Items by Interactions:\n",
      "app_id\n",
      "440        319492\n",
      "252490     270684\n",
      "1091500    226414\n",
      "730        219737\n",
      "570        216914\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Calculate Interaction Counts on Full Dataset\n",
    "print(\"Calculating interaction counts...\")\n",
    "\n",
    "# Count how many interactions each user has\n",
    "user_interaction_counts = recommendations_pd_full['user_id'].value_counts()\n",
    "\n",
    "# Count how many interactions each game (app_id) has\n",
    "item_interaction_counts = recommendations_pd_full['app_id'].value_counts()\n",
    "\n",
    "print(f\"Found {len(user_interaction_counts):,} unique users.\")\n",
    "print(f\"Found {len(item_interaction_counts):,} unique items (games) with interactions.\")\n",
    "\n",
    "# Display some stats about the counts (optional, but helpful for choosing thresholds)\n",
    "print(\"\\nUser Interaction Count Stats:\")\n",
    "print(user_interaction_counts.describe())\n",
    "print(\"\\nItem Interaction Count Stats:\")\n",
    "print(item_interaction_counts.describe())\n",
    "\n",
    "# Example: See the top 5 most active users and most interacted-with games\n",
    "print(\"\\nTop 5 Users by Interactions:\")\n",
    "print(user_interaction_counts.head())\n",
    "print(\"\\nTop 5 Items by Interactions:\")\n",
    "print(item_interaction_counts.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e017360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtering criteria: Users >= 20 interactions, Items >= 30000 interactions.\n",
      "Interactions after user filtering: 8,471,941\n",
      "Interactions after item filtering: 2,722,558\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 3: Filter Interactions Based on Thresholds\n",
    "\n",
    "# --- Define Thresholds ---\n",
    "# Adjusted based on your previous output/preference\n",
    "MIN_USER_INTERACTIONS = 20 # <-- INCREASED (Try 15, 20, 25, 30 etc.)\n",
    "MIN_ITEM_INTERACTIONS = 30000 # <-- Keep relatively low\n",
    "\n",
    "print(f\"\\nFiltering criteria: Users >= {MIN_USER_INTERACTIONS} interactions, Items >= {MIN_ITEM_INTERACTIONS} interactions.\")\n",
    "\n",
    "# --- Filter Users ---\n",
    "# Get the list of user_ids who meet the minimum interaction count\n",
    "users_to_keep = user_interaction_counts[user_interaction_counts >= MIN_USER_INTERACTIONS].index\n",
    "# Filter the main dataframe\n",
    "recommendations_pd_filtered_users = recommendations_pd_full[recommendations_pd_full['user_id'].isin(users_to_keep)]\n",
    "print(f\"Interactions after user filtering: {len(recommendations_pd_filtered_users):,}\")\n",
    "\n",
    "# --- Filter Items ---\n",
    "# Get the list of app_ids that meet the minimum interaction count\n",
    "items_to_keep = item_interaction_counts[item_interaction_counts >= MIN_ITEM_INTERACTIONS].index\n",
    "# Filter the dataframe that was already filtered by user\n",
    "recommendations_pd_filtered = recommendations_pd_filtered_users[recommendations_pd_filtered_users['app_id'].isin(items_to_keep)]\n",
    "print(f\"Interactions after item filtering: {len(recommendations_pd_filtered):,}\")\n",
    "\n",
    "# --- Cleanup intermediate variables ---\n",
    "del users_to_keep\n",
    "del items_to_keep\n",
    "del user_interaction_counts\n",
    "del item_interaction_counts\n",
    "del recommendations_pd_filtered_users\n",
    "del recommendations_pd_full\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b9e0ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtered interaction count: 2,722,558\n",
      "Shuffling the filtered data...\n",
      "Final number of interactions being used (shuffled): 2,722,558\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 4: Shuffle Filtered Data (No Sampling, Just Shuffle)\n",
    "\n",
    "SEED = 42 # For reproducible results\n",
    "\n",
    "print(f\"\\nFiltered interaction count: {len(recommendations_pd_filtered):,}\")\n",
    "print(\"Shuffling the filtered data...\")\n",
    "# Shuffle all rows using sample(frac=1) instead of sampling a subset\n",
    "recommendations_pd_final = recommendations_pd_filtered.sample(frac=1, random_state=SEED)\n",
    "\n",
    "print(f\"Final number of interactions being used (shuffled): {len(recommendations_pd_final):,}\")\n",
    "\n",
    "# --- Cleanup intermediate variable ---\n",
    "del recommendations_pd_filtered\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfa62b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Final Recommendations Data (Filtered & Shuffled):\n",
      "          app_id  helpful  funny   user_id  review_id  hours_log  \\\n",
      "5509481   230410        2      0   2905990    5509481   4.817051   \n",
      "25597948  238320       81      0  11844316   25597948   1.974081   \n",
      "2798083   261550        0      0   7230495    2798083   5.251750   \n",
      "24362024  460930        0      0   8966562   24362024   3.269569   \n",
      "12332588  286160        0      0   7626843   12332588   2.862201   \n",
      "\n",
      "          hours_log_scaled  is_recommended_binary  review_year  review_month  \\\n",
      "5509481           0.857725                      1         2018             1   \n",
      "25597948         -0.852292                      1         2014             3   \n",
      "2798083           1.119192                      1         2021            10   \n",
      "24362024         -0.073070                      1         2018            12   \n",
      "12332588         -0.318097                      1         2022             9   \n",
      "\n",
      "          review_day  review_age_years  helpfulness_ratio  helpful_log  \\\n",
      "5509481            7          6.984257           0.666667     1.098612   \n",
      "25597948          19         10.789870           0.987805     4.406719   \n",
      "2798083            4          3.244353           0.000000     0.000000   \n",
      "24362024          14          6.050650           0.000000     0.000000   \n",
      "12332588           1          2.335387           0.000000     0.000000   \n",
      "\n",
      "          funny_log  \n",
      "5509481         0.0  \n",
      "25597948        0.0  \n",
      "2798083         0.0  \n",
      "24362024        0.0  \n",
      "12332588        0.0  \n",
      "\n",
      "Unique Games in final dataset: 294\n",
      "\n",
      "Filtering Games Metadata...\n",
      "Retained metadata for 294 games.\n",
      "\n",
      "Sample Filtered Games Metadata (Relevant Columns):\n",
      "      app_id                           title  \\\n",
      "480   552520                      Far Cry® 5   \n",
      "1638  823500                       BONEWORKS   \n",
      "2002  613100                   House Flipper   \n",
      "2917  823130  Totally Accurate Battlegrounds   \n",
      "3149  466560                       Northgard   \n",
      "\n",
      "                                                   tags  \n",
      "480                                                  []  \n",
      "1638                                                 []  \n",
      "2002                                                 []  \n",
      "2917  ['Multiplayer', 'Physics', 'Indie', 'Character...  \n",
      "3149                                                 []  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 5: Display Sample Data and Finalize Game Metadata\n",
    "\n",
    "print(\"\\nSample Final Recommendations Data (Filtered & Shuffled):\")\n",
    "print(recommendations_pd_final.head())\n",
    "\n",
    "# Get unique game IDs from the final interaction dataset\n",
    "final_game_ids = recommendations_pd_final['app_id'].unique()\n",
    "print(f\"\\nUnique Games in final dataset: {len(final_game_ids):,}\")\n",
    "\n",
    "print(\"\\nFiltering Games Metadata...\")\n",
    "# Keep only metadata for games present in the final interaction data\n",
    "games_pd_filtered = games_pd[games_pd['app_id'].isin(final_game_ids)]\n",
    "print(f\"Retained metadata for {len(games_pd_filtered):,} games.\")\n",
    "\n",
    "print(\"\\nSample Filtered Games Metadata (Relevant Columns):\")\n",
    "print(games_pd_filtered[['app_id', 'title', 'tags']].head())\n",
    "\n",
    "# --- Final Cleanup for this Stage ---\n",
    "games_pd = games_pd_filtered\n",
    "\n",
    "# Delete the intermediate filtered variable and the IDs list\n",
    "del games_pd_filtered\n",
    "del final_game_ids\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6ca0493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the User-Item interaction matrix...\n",
      "Input data shape: (2722558, 15)\n",
      "Created pivot table with shape: (211442, 294) (Users x Items)\n",
      "Converting pivot table to sparse matrix (CSR format)...\n",
      "Sparse matrix shape: (211442, 294)\n",
      "Sparsity: 95.6204%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 6: Create User-Item Interaction Matrix\n",
    "# Needs recommendations_pd_final from Cell 4\n",
    "\n",
    "# from scipy.sparse import csr_matrix # Already imported\n",
    "\n",
    "print(\"Creating the User-Item interaction matrix...\")\n",
    "print(f\"Input data shape: {recommendations_pd_final.shape}\")\n",
    "\n",
    "# Define the interaction value column\n",
    "interaction_value_col = 'hours_log_scaled'\n",
    "\n",
    "# Use pivot_table to create the matrix (Users as rows, Items as columns)\n",
    "user_item_pivot = recommendations_pd_final.pivot_table(\n",
    "    index='user_id',\n",
    "    columns='app_id',\n",
    "    values=interaction_value_col,\n",
    "    fill_value=0  # Fill missing interactions (NaN) with 0\n",
    ")\n",
    "\n",
    "print(f\"Created pivot table with shape: {user_item_pivot.shape} (Users x Items)\")\n",
    "\n",
    "# Convert the dense pivot table to a sparse matrix (CSR format)\n",
    "print(\"Converting pivot table to sparse matrix (CSR format)...\")\n",
    "user_item_sparse_matrix = csr_matrix(user_item_pivot.values)\n",
    "\n",
    "# --- Create Mappings for Interpretation ---\n",
    "# These maps are essential to link matrix rows/columns back to original IDs\n",
    "user_map = {id: i for i, id in enumerate(user_item_pivot.index)}\n",
    "item_map = {id: i for i, id in enumerate(user_item_pivot.columns)} # Needed later\n",
    "\n",
    "# Create inverse mappings to get IDs from matrix indices\n",
    "user_map_inv = {i: id for id, i in user_map.items()}\n",
    "item_map_inv = {i: id for id, i in item_map.items()} # Needed later\n",
    "\n",
    "print(f\"Sparse matrix shape: {user_item_sparse_matrix.shape}\")\n",
    "sparsity = 1.0 - user_item_sparse_matrix.nnz / (user_item_sparse_matrix.shape[0] * user_item_sparse_matrix.shape[1])\n",
    "print(f\"Sparsity: {sparsity:.4%}\")\n",
    "\n",
    "# --- Cleanup ---\n",
    "del user_item_pivot\n",
    "del user_map\n",
    "del user_map_inv \n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b53e198d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Item-Item cosine similarity...\n",
      "Calculated item-item similarity matrix with shape: (294, 294)\n",
      "Diagonal check (should be close to 1): 0.9999999999999977\n",
      "\n",
      "Slice of the similarity matrix:\n",
      "          0         1         2         3         4\n",
      "0  1.000000  0.079481  0.064557  0.118324  0.048133\n",
      "1  0.079481  1.000000  0.213443  0.062399  0.157559\n",
      "2  0.064557  0.213443  1.000000  0.078867  0.166257\n",
      "3  0.118324  0.062399  0.078867  1.000000  0.054192\n",
      "4  0.048133  0.157559  0.166257  0.054192  1.000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 7: Calculate Item-Item Cosine Similarity\n",
    "\n",
    "print(\"Calculating Item-Item cosine similarity...\")\n",
    "\n",
    "# Important: cosine_similarity expects samples as rows.\n",
    "# To calculate item-item similarity, we transpose the matrix (.T) so that items become rows.\n",
    "item_user_sparse_matrix = user_item_sparse_matrix.T\n",
    "\n",
    "# Calculate cosine similarity between all pairs of items\n",
    "item_similarity_matrix = cosine_similarity(item_user_sparse_matrix, dense_output=True) # Keep dense\n",
    "\n",
    "print(f\"Calculated item-item similarity matrix with shape: {item_similarity_matrix.shape}\")\n",
    "\n",
    "# Optional: Verify the diagonal is all 1s\n",
    "print(f\"Diagonal check (should be close to 1): {item_similarity_matrix.diagonal().mean()}\")\n",
    "\n",
    "# Optional: Display a small slice\n",
    "print(\"\\nSlice of the similarity matrix:\")\n",
    "print(pd.DataFrame(item_similarity_matrix).iloc[:5, :5])\n",
    "\n",
    "# --- Cleanup ---\n",
    "del item_user_sparse_matrix\n",
    "del user_item_sparse_matrix\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "608b7f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing recommendation function with app_id: 400 ---\n",
      "--- Target Game: Portal ---\n",
      " app_id          game_name  similarity_score\n",
      "    620           Portal 2          0.180456\n",
      "    220        Half-Life 2          0.166257\n",
      "     70          Half-Life          0.157559\n",
      " 219150      Hotline Miami          0.121173\n",
      " 203160        Tomb Raider          0.108168\n",
      " 238320            Outlast          0.107559\n",
      " 424840  Little Nightmares          0.101653\n",
      "  50300 Spec Ops: The Line          0.096229\n",
      " 286690   Metro 2033 Redux          0.089345\n",
      " 239030      Papers Please          0.088623\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Define Item-Based Recommendation Function using Cosine Similarity\n",
    "\n",
    "def recommend_similar_games_cosine(target_app_id: int, top_n: int = 10) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Recommends games similar to the target_app_id using the pre-calculated\n",
    "    item-item cosine similarity matrix. Requires 'item_map', 'item_map_inv',\n",
    "    'item_similarity_matrix', and 'games_pd' to be in the global scope or passed explicitly.\n",
    "\n",
    "    Args:\n",
    "        target_app_id: The app_id of the game for which to find recommendations.\n",
    "        top_n: The number of similar games to return.\n",
    "\n",
    "    Returns:\n",
    "        A pandas DataFrame containing the top_n recommended games, including\n",
    "        their app_id, game_name, and similarity_score. Returns an empty\n",
    "        DataFrame if the target_app_id is not found in the model's data.\n",
    "    \"\"\"\n",
    "    # --- Input Validation ---\n",
    "    if target_app_id not in item_map:\n",
    "        print(f\"Warning: app_id {target_app_id} not found in the filtered interaction data.\")\n",
    "        return pd.DataFrame(columns=['app_id', 'game_name', 'similarity_score'])\n",
    "\n",
    "    # --- Get Matrix Index ---\n",
    "    try:\n",
    "        item_index = item_map[target_app_id]\n",
    "    except KeyError:\n",
    "        print(f\"Error: Could not find matrix index for app_id {target_app_id}.\")\n",
    "        return pd.DataFrame(columns=['app_id', 'game_name', 'similarity_score'])\n",
    "\n",
    "    # --- Retrieve Similarity Scores ---\n",
    "    similarity_scores = item_similarity_matrix[item_index]\n",
    "\n",
    "    # --- Combine Scores with Item Indices ---\n",
    "    item_score_pairs = list(enumerate(similarity_scores))\n",
    "\n",
    "    # --- Sort by Similarity ---\n",
    "    sorted_item_score_pairs = sorted(item_score_pairs, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # --- Exclude Input Game & Select Top N ---\n",
    "    top_similar_items = sorted_item_score_pairs[1 : top_n + 1]\n",
    "\n",
    "    # --- Map Indices back to App IDs and Get Names ---\n",
    "    recommendations = []\n",
    "    for matrix_idx, score in top_similar_items:\n",
    "        try:\n",
    "            recommended_app_id = item_map_inv[matrix_idx]\n",
    "            game_info = games_pd[games_pd['app_id'] == recommended_app_id]\n",
    "            game_name = game_info['title'].iloc[0] if not game_info.empty else \"Title Not Found\"\n",
    "            recommendations.append({\n",
    "                'app_id': recommended_app_id,\n",
    "                'game_name': game_name,\n",
    "                'similarity_score': score\n",
    "            })\n",
    "        except (KeyError, IndexError) as e:\n",
    "             print(f\"Warning: Error processing recommendation index {matrix_idx}: {e}\")\n",
    "\n",
    "    return pd.DataFrame(recommendations)\n",
    "\n",
    "# --- Quick Test ---\n",
    "if 'item_map' in globals() and item_map:\n",
    "    # Use a known good ID from your filtered set if possible, otherwise pick one\n",
    "    test_id_options = list(item_map.keys())\n",
    "    if test_id_options:\n",
    "         test_id = test_id_options[4] # Example: Pick 5th game ID\n",
    "         print(f\"\\n--- Testing recommendation function with app_id: {test_id} ---\")\n",
    "         # Look up name for context\n",
    "         test_name = games_pd.loc[games_pd['app_id'] == test_id, 'title'].iloc[0] if not games_pd[games_pd['app_id'] == test_id].empty else \"N/A\"\n",
    "         print(f\"--- Target Game: {test_name} ---\")\n",
    "         sample_recommendations = recommend_similar_games_cosine(test_id, top_n=10)\n",
    "         print(sample_recommendations.to_string(index=False)) # Print without index\n",
    "    else:\n",
    "        print(\"Skipping function test as item_map is empty.\")\n",
    "else:\n",
    "    print(\"Skipping function test as item_map is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "110c4bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving model artifacts...\n",
      "Saved item similarity matrix to: c:\\Users\\wbrya\\OneDrive\\Documents\\GitHub\\MovieLens-Recommender-System\\models\\item_similarity_matrix.pkl\n",
      "Saved item map to: c:\\Users\\wbrya\\OneDrive\\Documents\\GitHub\\MovieLens-Recommender-System\\models\\item_map.pkl\n",
      "Saved inverse item map to: c:\\Users\\wbrya\\OneDrive\\Documents\\GitHub\\MovieLens-Recommender-System\\models\\item_map_inv.pkl\n",
      "Saved filtered games metadata DataFrame to: c:\\Users\\wbrya\\OneDrive\\Documents\\GitHub\\MovieLens-Recommender-System\\models\\filtered_games_metadata.pkl\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Save Model Artifacts for Streamlit App\n",
    "\n",
    "print(\"\\nSaving model artifacts...\")\n",
    "\n",
    "# Define filenames for the artifacts\n",
    "similarity_matrix_filename = \"item_similarity_matrix.pkl\"\n",
    "item_map_filename = \"item_map.pkl\"\n",
    "item_map_inv_filename = \"item_map_inv.pkl\"\n",
    "games_df_filename = \"filtered_games_metadata.pkl\"\n",
    "\n",
    "# Define the target directory\n",
    "models_dir = os.path.join(BASE_DIR, \"models\")\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "# --- Save Objects ---\n",
    "# 1. Item-Item Cosine Similarity Matrix\n",
    "similarity_matrix_path = os.path.join(models_dir, similarity_matrix_filename)\n",
    "with open(similarity_matrix_path, 'wb') as f:\n",
    "    pickle.dump(item_similarity_matrix, f)\n",
    "print(f\"Saved item similarity matrix to: {similarity_matrix_path}\")\n",
    "\n",
    "# 2. Item Map (app_id -> matrix index)\n",
    "item_map_path = os.path.join(models_dir, item_map_filename)\n",
    "with open(item_map_path, 'wb') as f:\n",
    "    pickle.dump(item_map, f)\n",
    "print(f\"Saved item map to: {item_map_path}\")\n",
    "\n",
    "# 3. Inverse Item Map (matrix index -> app_id)\n",
    "item_map_inv_path = os.path.join(models_dir, item_map_inv_filename)\n",
    "with open(item_map_inv_path, 'wb') as f:\n",
    "    pickle.dump(item_map_inv, f)\n",
    "print(f\"Saved inverse item map to: {item_map_inv_path}\")\n",
    "\n",
    "# 4. Filtered Games DataFrame\n",
    "games_df_path = os.path.join(models_dir, games_df_filename)\n",
    "with open(games_df_path, 'wb') as f:\n",
    "    pickle.dump(games_pd, f)\n",
    "print(f\"Saved filtered games metadata DataFrame to: {games_df_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b9dccad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing train-test split...\n",
      "Original interactions: 2,722,558\n",
      "Training interactions: 2,178,404\n",
      "Testing interactions:  544,154\n",
      "\n",
      "Users in training map: 211,442\n",
      "Users in testing map:  203,335\n",
      "Valid users for evaluation: 104,089\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 10: Create Train-Test Split for Evaluation\n",
    "\n",
    "print(\"\\nPerforming train-test split...\")\n",
    "\n",
    "# --- Parameters ---\n",
    "test_fraction = 0.2 # Fraction of interactions per user to hold out for testing\n",
    "min_train_interactions = 10 # Minimum interactions a user must have in the training set\n",
    "\n",
    "# --- Split Data ---\n",
    "test_indices = recommendations_pd_final.groupby('user_id').sample(frac=test_fraction, random_state=SEED).index\n",
    "train_indices = recommendations_pd_final.index.difference(test_indices)\n",
    "\n",
    "train_df = recommendations_pd_final.loc[train_indices]\n",
    "test_df = recommendations_pd_final.loc[test_indices]\n",
    "\n",
    "print(f\"Original interactions: {len(recommendations_pd_final):,}\")\n",
    "print(f\"Training interactions: {len(train_df):,}\")\n",
    "print(f\"Testing interactions:  {len(test_df):,}\")\n",
    "\n",
    "# --- Create User-to-Items Mappings ---\n",
    "train_items_map: Dict[int, Set[int]] = train_df.groupby('user_id')['app_id'].apply(set)\n",
    "test_items_map: Dict[int, Set[int]] = test_df.groupby('user_id')['app_id'].apply(set)\n",
    "\n",
    "print(f\"\\nUsers in training map: {len(train_items_map):,}\")\n",
    "print(f\"Users in testing map:  {len(test_items_map):,}\")\n",
    "\n",
    "# --- Filter Test Users ---\n",
    "valid_test_user_ids = {\n",
    "    user_id for user_id, train_items in train_items_map.items()\n",
    "    if user_id in test_items_map and len(train_items) >= min_train_interactions\n",
    "}\n",
    "\n",
    "# Filter the test map\n",
    "filtered_test_items_map = {\n",
    "    user_id: items for user_id, items in test_items_map.items()\n",
    "    if user_id in valid_test_user_ids\n",
    "}\n",
    "\n",
    "print(f\"Valid users for evaluation: {len(valid_test_user_ids):,}\")\n",
    "\n",
    "# --- Cleanup (Optional) ---\n",
    "# We need train_items_map, filtered_test_items_map, valid_test_user_ids for Cell 13 & 14\n",
    "del test_indices\n",
    "del train_indices\n",
    "del test_df # test_df itself not directly used after creating map\n",
    "del train_df # train_df itself not directly used after creating map\n",
    "del recommendations_pd_final # Original shuffled/filtered list no longer needed\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ed3780d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: User Recommendation Function (for Evaluation)\n",
    "\n",
    "def recommend_for_user(\n",
    "    user_id: int,\n",
    "    k: int,\n",
    "    train_items_map: Dict[int, Set[int]],\n",
    "    item_similarity_matrix: np.ndarray,\n",
    "    item_map: Dict[int, int],\n",
    "    item_map_inv: Dict[int, int]\n",
    ") -> List[int]:\n",
    "    \"\"\"\n",
    "    Generates top K recommendations for a user based on their training interactions\n",
    "    using the item-item similarity matrix.\n",
    "    \"\"\"\n",
    "    if user_id not in train_items_map or not train_items_map[user_id]:\n",
    "        return []\n",
    "\n",
    "    user_train_app_ids = train_items_map[user_id]\n",
    "    n_items = item_similarity_matrix.shape[0]\n",
    "    aggregated_scores = np.zeros(n_items)\n",
    "\n",
    "    user_train_indices = {item_map[app_id] for app_id in user_train_app_ids if app_id in item_map}\n",
    "\n",
    "    if not user_train_indices:\n",
    "        return []\n",
    "\n",
    "    for train_idx in user_train_indices:\n",
    "        if 0 <= train_idx < n_items:\n",
    "             aggregated_scores += item_similarity_matrix[train_idx]\n",
    "\n",
    "    candidate_items = []\n",
    "    for item_idx in range(n_items):\n",
    "        if item_idx not in user_train_indices and item_idx in item_map_inv:\n",
    "             candidate_items.append((item_idx, aggregated_scores[item_idx]))\n",
    "\n",
    "    candidate_items.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    recommended_app_ids = [item_map_inv[item_idx] for item_idx, score in candidate_items[:k]]\n",
    "\n",
    "    return recommended_app_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "037538e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Evaluation Metric Functions\n",
    "\n",
    "def precision_at_k(recommended_items: List[int], actual_items: Set[int], k: int) -> float:\n",
    "    \"\"\"Calculates Precision@K.\"\"\"\n",
    "    if k == 0: return 0.0\n",
    "    top_k_recs = recommended_items[:k]\n",
    "    hits = len(set(top_k_recs) & actual_items)\n",
    "    return hits / k\n",
    "\n",
    "def recall_at_k(recommended_items: List[int], actual_items: Set[int], k: int) -> float:\n",
    "    \"\"\"Calculates Recall@K.\"\"\"\n",
    "    if not actual_items: return 0.0\n",
    "    top_k_recs = recommended_items[:k]\n",
    "    hits = len(set(top_k_recs) & actual_items)\n",
    "    return hits / len(actual_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90ce8810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running evaluation...\n",
      "Evaluating 104,089 users...\n",
      "  Evaluated 5000/104089 users...\n",
      "  Evaluated 10000/104089 users...\n",
      "  Evaluated 15000/104089 users...\n",
      "  Evaluated 20000/104089 users...\n",
      "  Evaluated 25000/104089 users...\n",
      "  Evaluated 30000/104089 users...\n",
      "  Evaluated 35000/104089 users...\n",
      "  Evaluated 40000/104089 users...\n",
      "  Evaluated 45000/104089 users...\n",
      "  Evaluated 50000/104089 users...\n",
      "  Evaluated 55000/104089 users...\n",
      "  Evaluated 60000/104089 users...\n",
      "  Evaluated 65000/104089 users...\n",
      "  Evaluated 70000/104089 users...\n",
      "  Evaluated 75000/104089 users...\n",
      "  Evaluated 80000/104089 users...\n",
      "  Evaluated 85000/104089 users...\n",
      "  Evaluated 90000/104089 users...\n",
      "  Evaluated 95000/104089 users...\n",
      "  Evaluated 100000/104089 users...\n",
      "  Evaluated 104089/104089 users...\n",
      "\n",
      "--- Evaluation Results (K=20) ---\n",
      "Evaluated users: 104,089\n",
      "Average Precision@20: 0.0560\n",
      "Average Recall@20:    0.2978\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 13: Run Evaluation\n",
    "\n",
    "print(\"\\nRunning evaluation...\")\n",
    "\n",
    "# --- Evaluation Parameters ---\n",
    "K = 20\n",
    "\n",
    "# --- Store Results ---\n",
    "all_precisions = []\n",
    "all_recalls = []\n",
    "\n",
    "# --- Iterate Through Test Users ---\n",
    "num_evaluated = 0\n",
    "total_users_to_evaluate = len(valid_test_user_ids)\n",
    "print(f\"Evaluating {total_users_to_evaluate:,} users...\")\n",
    "\n",
    "for i, user_id in enumerate(valid_test_user_ids):\n",
    "    actual_items = filtered_test_items_map.get(user_id, set())\n",
    "    if not actual_items: continue\n",
    "\n",
    "    recommended_ids = recommend_for_user(\n",
    "        user_id=user_id, k=K, train_items_map=train_items_map,\n",
    "        item_similarity_matrix=item_similarity_matrix,\n",
    "        item_map=item_map, item_map_inv=item_map_inv\n",
    "    )\n",
    "\n",
    "    precision = precision_at_k(recommended_ids, actual_items, K)\n",
    "    recall = recall_at_k(recommended_ids, actual_items, K)\n",
    "\n",
    "    all_precisions.append(precision)\n",
    "    all_recalls.append(recall)\n",
    "    num_evaluated += 1\n",
    "\n",
    "    # Print progress\n",
    "    if (i + 1) % 5000 == 0 or (i + 1) == total_users_to_evaluate:\n",
    "        print(f\"  Evaluated {i + 1}/{total_users_to_evaluate} users...\")\n",
    "\n",
    "# --- Calculate Average Metrics ---\n",
    "if num_evaluated > 0:\n",
    "    avg_precision = np.mean(all_precisions)\n",
    "    avg_recall = np.mean(all_recalls)\n",
    "\n",
    "    print(f\"\\n--- Evaluation Results (K={K}) ---\")\n",
    "    print(f\"Evaluated users: {num_evaluated:,}\")\n",
    "    print(f\"Average Precision@{K}: {avg_precision:.4f}\")\n",
    "    print(f\"Average Recall@{K}:    {avg_recall:.4f}\")\n",
    "else:\n",
    "    print(\"No valid users found to evaluate.\")\n",
    "\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
